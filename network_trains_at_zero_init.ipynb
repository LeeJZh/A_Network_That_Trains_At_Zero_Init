{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "network_trains_at_zero_init.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeJZh/A_Network_That_Trains_At_Zero_Init/blob/master/network_trains_at_zero_init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrhPQRJgic2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "F-DHZtitic20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_set = datasets.MNIST(root=\"./mnist_data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test_set = datasets.MNIST(root=\"./mnist_data\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRog0H-5ic23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_loader = torch.utils.data.DataLoader(mnist_set, 36)\n",
        "mnist_test_loader = torch.utils.data.DataLoader(mnist_test_set, 36)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ctpZ9fbPic25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "4978c703-fdbe-447b-b6c2-e08078b47411"
      },
      "source": [
        "class Selection(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.c_in = in_channels\n",
        "        self.counter = 0\n",
        "        self.clf = nn.Linear(in_channels, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.counter == -1:\n",
        "            out = self.clf(x)\n",
        "\n",
        "        elif self.counter + 10 <= self.c_in:\n",
        "            print(\"couter: {}\".format(self.counter))\n",
        "            out = x[:, self.counter: self.counter+10]\n",
        "            self.counter += 10\n",
        "        \n",
        "        else:\n",
        "            out = x[:, -10:]\n",
        "            self.counter = -1\n",
        "        \n",
        "        return out\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        c_in = 28 * 28\n",
        "        c_out= 512\n",
        "        linears = []\n",
        "        selectors = []\n",
        "        for _ in range(5):\n",
        "            linears += [nn.Linear(c_in, c_out)]\n",
        "            selectors += [Selection(c_out)]\n",
        "            c_in, cout = c_out, c_out // 2\n",
        "        \n",
        "        self.clf = nn.Linear(c_out, 10)\n",
        "        self.linears = nn.ModuleList(linears)\n",
        "        self.selectors = nn.ModuleList(selectors)\n",
        "        # self.clfs = nn.ModuleList(clfs)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        features = [x]\n",
        "        outputs = []\n",
        "        for l, s in zip(self.linears, self.selectors):\n",
        "            feature = l(features[-1])\n",
        "            # perm = torch.randperm(feature.size(1))\n",
        "            outputs += [s(feature)]\n",
        "            features += [self.act(feature)]\n",
        "        outputs += [self.clf(feature)]\n",
        "        return outputs\n",
        "\n",
        "net = MLP().cuda()\n",
        "for name, p in net.named_parameters():\n",
        "    print(name, p.size())\n",
        "    torch.nn.init.constant_(p, 0.0)\n",
        "    print(p.data.sum())\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "adam = torch.optim.Adam(net.parameters(), lr=3e-4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.0.weight torch.Size([512, 784])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.0.bias torch.Size([512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.1.weight torch.Size([512, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.1.bias torch.Size([512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.2.weight torch.Size([512, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.2.bias torch.Size([512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.3.weight torch.Size([512, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.3.bias torch.Size([512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.4.weight torch.Size([512, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "linears.4.bias torch.Size([512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.0.clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.0.clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.1.clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.1.clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.2.clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.2.clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.3.clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.3.clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.4.clf.weight torch.Size([10, 512])\n",
            "tensor(0., device='cuda:0')\n",
            "selectors.4.clf.bias torch.Size([10])\n",
            "tensor(0., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "b7AdPlp7ic29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6adf866f-4ab8-4f30-edde-91f370593e17"
      },
      "source": [
        "def train_one_epoch():\n",
        "    for x, y in mnist_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        adam.zero_grad()\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        y_hat_list = net(x)\n",
        "        loss = 0.0\n",
        "\n",
        "        for y_hat in y_hat_list:\n",
        "            loss += criterion(y_hat, y)\n",
        "    \n",
        "        loss.backward()\n",
        "        adam.step()\n",
        "    print(\"loss: {:.4f}\".format(loss.item()))\n",
        "\n",
        "for i in range(3):\n",
        "    # print(\"training epoch {}\".format(i))\n",
        "    train_one_epoch()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "couter: 0\n",
            "couter: 0\n",
            "couter: 0\n",
            "couter: 0\n",
            "couter: 0\n",
            "couter: 10\n",
            "couter: 10\n",
            "couter: 10\n",
            "couter: 10\n",
            "couter: 10\n",
            "couter: 20\n",
            "couter: 20\n",
            "couter: 20\n",
            "couter: 20\n",
            "couter: 20\n",
            "couter: 30\n",
            "couter: 30\n",
            "couter: 30\n",
            "couter: 30\n",
            "couter: 30\n",
            "couter: 40\n",
            "couter: 40\n",
            "couter: 40\n",
            "couter: 40\n",
            "couter: 40\n",
            "couter: 50\n",
            "couter: 50\n",
            "couter: 50\n",
            "couter: 50\n",
            "couter: 50\n",
            "couter: 60\n",
            "couter: 60\n",
            "couter: 60\n",
            "couter: 60\n",
            "couter: 60\n",
            "couter: 70\n",
            "couter: 70\n",
            "couter: 70\n",
            "couter: 70\n",
            "couter: 70\n",
            "couter: 80\n",
            "couter: 80\n",
            "couter: 80\n",
            "couter: 80\n",
            "couter: 80\n",
            "couter: 90\n",
            "couter: 90\n",
            "couter: 90\n",
            "couter: 90\n",
            "couter: 90\n",
            "couter: 100\n",
            "couter: 100\n",
            "couter: 100\n",
            "couter: 100\n",
            "couter: 100\n",
            "couter: 110\n",
            "couter: 110\n",
            "couter: 110\n",
            "couter: 110\n",
            "couter: 110\n",
            "couter: 120\n",
            "couter: 120\n",
            "couter: 120\n",
            "couter: 120\n",
            "couter: 120\n",
            "couter: 130\n",
            "couter: 130\n",
            "couter: 130\n",
            "couter: 130\n",
            "couter: 130\n",
            "couter: 140\n",
            "couter: 140\n",
            "couter: 140\n",
            "couter: 140\n",
            "couter: 140\n",
            "couter: 150\n",
            "couter: 150\n",
            "couter: 150\n",
            "couter: 150\n",
            "couter: 150\n",
            "couter: 160\n",
            "couter: 160\n",
            "couter: 160\n",
            "couter: 160\n",
            "couter: 160\n",
            "couter: 170\n",
            "couter: 170\n",
            "couter: 170\n",
            "couter: 170\n",
            "couter: 170\n",
            "couter: 180\n",
            "couter: 180\n",
            "couter: 180\n",
            "couter: 180\n",
            "couter: 180\n",
            "couter: 190\n",
            "couter: 190\n",
            "couter: 190\n",
            "couter: 190\n",
            "couter: 190\n",
            "couter: 200\n",
            "couter: 200\n",
            "couter: 200\n",
            "couter: 200\n",
            "couter: 200\n",
            "couter: 210\n",
            "couter: 210\n",
            "couter: 210\n",
            "couter: 210\n",
            "couter: 210\n",
            "couter: 220\n",
            "couter: 220\n",
            "couter: 220\n",
            "couter: 220\n",
            "couter: 220\n",
            "couter: 230\n",
            "couter: 230\n",
            "couter: 230\n",
            "couter: 230\n",
            "couter: 230\n",
            "couter: 240\n",
            "couter: 240\n",
            "couter: 240\n",
            "couter: 240\n",
            "couter: 240\n",
            "couter: 250\n",
            "couter: 250\n",
            "couter: 250\n",
            "couter: 250\n",
            "couter: 250\n",
            "couter: 260\n",
            "couter: 260\n",
            "couter: 260\n",
            "couter: 260\n",
            "couter: 260\n",
            "couter: 270\n",
            "couter: 270\n",
            "couter: 270\n",
            "couter: 270\n",
            "couter: 270\n",
            "couter: 280\n",
            "couter: 280\n",
            "couter: 280\n",
            "couter: 280\n",
            "couter: 280\n",
            "couter: 290\n",
            "couter: 290\n",
            "couter: 290\n",
            "couter: 290\n",
            "couter: 290\n",
            "couter: 300\n",
            "couter: 300\n",
            "couter: 300\n",
            "couter: 300\n",
            "couter: 300\n",
            "couter: 310\n",
            "couter: 310\n",
            "couter: 310\n",
            "couter: 310\n",
            "couter: 310\n",
            "couter: 320\n",
            "couter: 320\n",
            "couter: 320\n",
            "couter: 320\n",
            "couter: 320\n",
            "couter: 330\n",
            "couter: 330\n",
            "couter: 330\n",
            "couter: 330\n",
            "couter: 330\n",
            "couter: 340\n",
            "couter: 340\n",
            "couter: 340\n",
            "couter: 340\n",
            "couter: 340\n",
            "couter: 350\n",
            "couter: 350\n",
            "couter: 350\n",
            "couter: 350\n",
            "couter: 350\n",
            "couter: 360\n",
            "couter: 360\n",
            "couter: 360\n",
            "couter: 360\n",
            "couter: 360\n",
            "couter: 370\n",
            "couter: 370\n",
            "couter: 370\n",
            "couter: 370\n",
            "couter: 370\n",
            "couter: 380\n",
            "couter: 380\n",
            "couter: 380\n",
            "couter: 380\n",
            "couter: 380\n",
            "couter: 390\n",
            "couter: 390\n",
            "couter: 390\n",
            "couter: 390\n",
            "couter: 390\n",
            "couter: 400\n",
            "couter: 400\n",
            "couter: 400\n",
            "couter: 400\n",
            "couter: 400\n",
            "couter: 410\n",
            "couter: 410\n",
            "couter: 410\n",
            "couter: 410\n",
            "couter: 410\n",
            "couter: 420\n",
            "couter: 420\n",
            "couter: 420\n",
            "couter: 420\n",
            "couter: 420\n",
            "couter: 430\n",
            "couter: 430\n",
            "couter: 430\n",
            "couter: 430\n",
            "couter: 430\n",
            "couter: 440\n",
            "couter: 440\n",
            "couter: 440\n",
            "couter: 440\n",
            "couter: 440\n",
            "couter: 450\n",
            "couter: 450\n",
            "couter: 450\n",
            "couter: 450\n",
            "couter: 450\n",
            "couter: 460\n",
            "couter: 460\n",
            "couter: 460\n",
            "couter: 460\n",
            "couter: 460\n",
            "couter: 470\n",
            "couter: 470\n",
            "couter: 470\n",
            "couter: 470\n",
            "couter: 470\n",
            "couter: 480\n",
            "couter: 480\n",
            "couter: 480\n",
            "couter: 480\n",
            "couter: 480\n",
            "couter: 490\n",
            "couter: 490\n",
            "couter: 490\n",
            "couter: 490\n",
            "couter: 490\n",
            "couter: 500\n",
            "couter: 500\n",
            "couter: 500\n",
            "couter: 500\n",
            "couter: 500\n",
            "loss: 0.2255\n",
            "loss: 0.0987\n",
            "loss: 0.0675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNRuC0J2ic2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(logit, target):\n",
        "    predication = torch.argmax(logit, dim=1)\n",
        "    return (predication == target).to(torch.float)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "9KjgPoVUic3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b066ece-a3a2-4c6a-e1a5-1c3a741639de"
      },
      "source": [
        "res = None\n",
        "# net.cpu()\n",
        "for x, y in mnist_test_loader:\n",
        "    x, y = x.cuda(), y.cuda()\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        if res is None:\n",
        "            res = acc(net(x)[-1], y)\n",
        "        else:\n",
        "            res = torch.cat([res, acc(net(x)[-1], y)], dim=0)\n",
        "    \n",
        "print(res.mean())\n",
        "\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9636, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "2gFJ3VNaic3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "5ee37183-20a4-4269-a2ae-4041e4942841"
      },
      "source": [
        "for name, p in net.named_parameters():\n",
        "    print(name, p.data.sum(), p.data.mean(), (p.data < 1e-4).to(torch.float).mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf.weight tensor(0.1329, device='cuda:0') tensor(2.5948e-05, device='cuda:0') tensor(0.5002, device='cuda:0')\n",
            "clf.bias tensor(-0.0396, device='cuda:0') tensor(-0.0040, device='cuda:0') tensor(0.5000, device='cuda:0')\n",
            "linears.0.weight tensor(-1434.9075, device='cuda:0') tensor(-0.0036, device='cuda:0') tensor(0.5875, device='cuda:0')\n",
            "linears.0.bias tensor(0.2986, device='cuda:0') tensor(0.0006, device='cuda:0') tensor(0.4434, device='cuda:0')\n",
            "linears.1.weight tensor(61.3044, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(0.4917, device='cuda:0')\n",
            "linears.1.bias tensor(-1.7179, device='cuda:0') tensor(-0.0034, device='cuda:0') tensor(0.5605, device='cuda:0')\n",
            "linears.2.weight tensor(-926.9553, device='cuda:0') tensor(-0.0035, device='cuda:0') tensor(0.6144, device='cuda:0')\n",
            "linears.2.bias tensor(-3.9924, device='cuda:0') tensor(-0.0078, device='cuda:0') tensor(0.5938, device='cuda:0')\n",
            "linears.3.weight tensor(-841.5667, device='cuda:0') tensor(-0.0032, device='cuda:0') tensor(0.5824, device='cuda:0')\n",
            "linears.3.bias tensor(6.9784, device='cuda:0') tensor(0.0136, device='cuda:0') tensor(0.4062, device='cuda:0')\n",
            "linears.4.weight tensor(6.8010, device='cuda:0') tensor(2.5944e-05, device='cuda:0') tensor(0.5065, device='cuda:0')\n",
            "linears.4.bias tensor(0.4683, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(0.4805, device='cuda:0')\n",
            "selectors.0.clf.weight tensor(-21.5364, device='cuda:0') tensor(-0.0042, device='cuda:0') tensor(0.5945, device='cuda:0')\n",
            "selectors.0.clf.bias tensor(-0.0018, device='cuda:0') tensor(-0.0002, device='cuda:0') tensor(0.5000, device='cuda:0')\n",
            "selectors.1.clf.weight tensor(-16.7525, device='cuda:0') tensor(-0.0033, device='cuda:0') tensor(0.5977, device='cuda:0')\n",
            "selectors.1.clf.bias tensor(-0.0193, device='cuda:0') tensor(-0.0019, device='cuda:0') tensor(0.5000, device='cuda:0')\n",
            "selectors.2.clf.weight tensor(-1.7489, device='cuda:0') tensor(-0.0003, device='cuda:0') tensor(0.6064, device='cuda:0')\n",
            "selectors.2.clf.bias tensor(-0.0225, device='cuda:0') tensor(-0.0023, device='cuda:0') tensor(0.6000, device='cuda:0')\n",
            "selectors.3.clf.weight tensor(0.8036, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(0.5418, device='cuda:0')\n",
            "selectors.3.clf.bias tensor(-0.0882, device='cuda:0') tensor(-0.0088, device='cuda:0') tensor(0.5000, device='cuda:0')\n",
            "selectors.4.clf.weight tensor(-0.0033, device='cuda:0') tensor(-6.4368e-07, device='cuda:0') tensor(0.5000, device='cuda:0')\n",
            "selectors.4.clf.bias tensor(-0.0416, device='cuda:0') tensor(-0.0042, device='cuda:0') tensor(0.6000, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pRovdQdic3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}