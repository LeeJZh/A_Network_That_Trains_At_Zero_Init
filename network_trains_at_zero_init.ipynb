{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit929d5798b1124dfbac76e75bc1bca880",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_set = datasets.MNIST(root=\"./mnist_data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test_set = datasets.MNIST(root=\"./mnist_data\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loader = torch.utils.data.DataLoader(mnist_set, 36)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(mnist_test_set, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "clf.weight torch.Size([10, 512])\ntensor(0.)\nclf.bias torch.Size([10])\ntensor(0.)\nlinears.0.weight torch.Size([512, 784])\ntensor(0.)\nlinears.0.bias torch.Size([512])\ntensor(0.)\nlinears.1.weight torch.Size([512, 512])\ntensor(0.)\nlinears.1.bias torch.Size([512])\ntensor(0.)\nlinears.2.weight torch.Size([512, 512])\ntensor(0.)\nlinears.2.bias torch.Size([512])\ntensor(0.)\nlinears.3.weight torch.Size([512, 512])\ntensor(0.)\nlinears.3.bias torch.Size([512])\ntensor(0.)\nlinears.4.weight torch.Size([512, 512])\ntensor(0.)\nlinears.4.bias torch.Size([512])\ntensor(0.)\n"
    }
   ],
   "source": [
    "class Selection(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.c_in = in_channels\n",
    "        self.counter = 0\n",
    "        self.clf = nn.Linear(in_features, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.counter == -1:\n",
    "            out = self.clf(x)\n",
    "\n",
    "        elif self.counter + 10 <= self.c_in:\n",
    "            out = x[:, self.counter: self.counter+10]\n",
    "            self.counter += 10\n",
    "        \n",
    "        else:\n",
    "            out = x[:, -10:]\n",
    "            self.counter = -1\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_in = 28 * 28\n",
    "        c_out= 512\n",
    "        linears = []\n",
    "        # clfs = []\n",
    "        selectors = []\n",
    "        for _ in range(5):\n",
    "            linears += [nn.Linear(c_in, c_out)]\n",
    "            # clfs += [nn.Linear(c_out, 10)]\n",
    "            selectors += [Selection(c_out)]\n",
    "            c_in, cout = c_out, c_out // 2\n",
    "        \n",
    "        self.clf = nn.Linear(c_out, 10)\n",
    "        \n",
    "        self.linears = nn.ModuleList(linears)\n",
    "        self.selectors = nn.ModuleList(selectors)\n",
    "        # self.clfs = nn.ModuleList(clfs)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        outputs = []\n",
    "        for l, s in zip(self.linears, self.selectors):\n",
    "            feature = l(features[-1])\n",
    "            # perm = torch.randperm(feature.size(1))\n",
    "            outputs += [s(feature)]\n",
    "            features += [self.act(feature)]\n",
    "        outputs += [self.clf(feature)]\n",
    "        return outputs\n",
    "\n",
    "net = MLP().cuda()\n",
    "for name, p in net.named_parameters():\n",
    "    print(name, p.size())\n",
    "    torch.nn.init.constant_(p, 0.0)\n",
    "    print(p.data.sum())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "adam = torch.optim.Adam(net.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loss: 1.0552\nloss: 0.6074\nloss: 0.5476\n"
    }
   ],
   "source": [
    "def train_one_epoch():\n",
    "    for x, y in mnist_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        adam.zero_grad()\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        y_hat_list = net(x)\n",
    "        loss = 0.0\n",
    "\n",
    "        for y_hat in y_hat_list:\n",
    "            loss += criterion(y_hat, y)\n",
    "    \n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "    print(\"loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "for i in range(3):\n",
    "    # print(\"training epoch {}\".format(i))\n",
    "    train_one_epoch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(logit, target):\n",
    "    predication = torch.argmax(logit, dim=1)\n",
    "    return (predication == target).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9293279611378265\n"
    }
   ],
   "source": [
    "res = None\n",
    "for x, y in mnist_test_loader:\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        if res is None:\n",
    "            res = acc(net(x)[-1], y)\n",
    "        else:\n",
    "            res = torch.cat([res, acc(net(x)[-1], y)])\n",
    "    \n",
    "print(res.mean())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "clf.weight tensor(-4.2497) tensor(-0.0008) tensor(0.6049)\nclf.bias tensor(0.0217) tensor(0.0022) tensor(0.4000)\nlinears.0.weight tensor(-2496.5786) tensor(-0.0062) tensor(0.6172)\nlinears.0.bias tensor(-6.8054) tensor(-0.0133) tensor(0.5820)\nlinears.1.weight tensor(-269.0327) tensor(-0.0010) tensor(0.5506)\nlinears.1.bias tensor(1.9512) tensor(0.0038) tensor(0.5059)\nlinears.2.weight tensor(-376.4302) tensor(-0.0014) tensor(0.5540)\nlinears.2.bias tensor(7.0401) tensor(0.0138) tensor(0.3125)\nlinears.3.weight tensor(-1322.2778) tensor(-0.0050) tensor(0.7080)\nlinears.3.bias tensor(-3.1884) tensor(-0.0062) tensor(0.7402)\nlinears.4.weight tensor(-367.5648) tensor(-0.0014) tensor(0.6515)\nlinears.4.bias tensor(3.2873) tensor(0.0064) tensor(0.3398)\n"
    }
   ],
   "source": [
    "for name, p in net.named_parameters():\n",
    "    print(name, p.data.sum(), p.data.mean(), (p.data < 1e-4).to(torch.float).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}